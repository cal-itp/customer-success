{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Requires a HubSpot Private app with an API access token with the following scopes:\n",
        "\n",
        "- `crm.schemas.custom.read`\n",
        "- `crm.objects.custom.read`\n",
        "- `crm.objects.custom.write`\n",
        "- `crm.objects.companies.read`\n",
        "- `crm.schemas.contacts.read`\n",
        "- `crm.objects.contacts.read`\n",
        "- `crm.schemas.companies.read`\n",
        "- `sales-email-read`\n",
        "\n",
        "The token should be stored in an environment variable called `HUBSPOT_ACCESS_TOKEN`.\n",
        "\n",
        "You can copy the sample environment file to get started; run the following command from the root of this repository:\n",
        "\n",
        "```bash\n",
        "cp .env.sample .env\n",
        "```\n",
        "\n",
        "Then open `.env` and fill in with your access token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from hubspot import HubSpot\n",
        "from hubspot.crm.associations.v4.models import AssociationSpec, BatchInputPublicAssociationMultiPost, PublicAssociationMultiPost\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "ACCESS_TOKEN = os.environ[\"HUBSPOT_ACCESS_TOKEN\"]\n",
        "ASSOCIATION_TYPES = [\"calls\", \"emails\", \"meetings\", \"notes\", \"tasks\"]\n",
        "\n",
        "hubspot = HubSpot(access_token=ACCESS_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_json_records(df: pd.DataFrame, file_path: str):\n",
        "    \"\"\"Helper writes the DataFrame into a JSON file.\"\"\"\n",
        "    df.to_json(f\"data/{file_path}\", orient=\"records\", indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RunMode:\n",
        "    FULL = 0\n",
        "    DRY = 1\n",
        "    LIVE = 2\n",
        "\n",
        "\n",
        "RUN_MODE = int(os.environ.get(\"HUBSPOT_VENDORS_RUN_MODE\", RunMode.DRY))\n",
        "print(f\"Run mode: {RUN_MODE}\")\n",
        "\n",
        "if RUN_MODE == RunMode.FULL:\n",
        "    [f.unlink() for f in Path(\"data\").iterdir()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get vendor data\n",
        "\n",
        "In this section we request data for the objects we'll be interacting with:\n",
        "\n",
        "- `companies` (built-in)\n",
        "- `vendors` (custom)\n",
        "\n",
        "We start by requesting the set of properties for these objects for documentation and hints for later analysis.\n",
        "\n",
        "Then we get companies, and filter for those with property `company_type == \"Vendor\"`.\n",
        "\n",
        "Finally, we get the vendor custom objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# request company properties and read into DataFrame\n",
        "if RUN_MODE == RunMode.FULL:\n",
        "    company_props = hubspot.crm.properties.core_api.get_all(object_type=\"companies\", archived=False)\n",
        "    company_props_df = pd.json_normalize(company_props.to_dict(), \"results\")\n",
        "    write_json_records(company_props_df, \"company_props.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# request companies data\n",
        "companies = hubspot.crm.companies.get_all(properties=[\"company_type\", \"domain\", \"name\"], associations=ASSOCIATION_TYPES)\n",
        "companies = [c.to_dict() for c in companies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read companies data into DataFrame\n",
        "companies_df = pd.json_normalize(companies)\n",
        "companies_df[\"properties.domain\"] = companies_df[\"properties.domain\"].astype(\"category\")\n",
        "if RUN_MODE == RunMode.FULL:\n",
        "    write_json_records(companies_df, \"company_all.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# look at the unique company types defined\n",
        "if RUN_MODE == RunMode.FULL:\n",
        "    company_types = companies_df[\"properties.company_type\"].unique()\n",
        "    company_types.tofile(\"data/company_types.txt\", sep=os.linesep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter vendor companies into new DataFrame\n",
        "vendor_companies_df = companies_df[companies_df[\"properties.company_type\"] == \"Vendor\"]\n",
        "if RUN_MODE == RunMode.FULL:\n",
        "    write_json_records(vendor_companies_df, \"company_vendors.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# request vendor properties and read into DataFrame\n",
        "if RUN_MODE == RunMode.FULL:\n",
        "    vendor_props = hubspot.crm.properties.core_api.get_all(object_type=\"vendors\", archived=False)\n",
        "    vendor_props_df = pd.json_normalize(vendor_props.to_dict(), \"results\")\n",
        "    write_json_records(vendor_props_df, \"vendor_props.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# request vendor data\n",
        "vendors = hubspot.crm.objects.get_all(\"vendors\", properties=[\"domain\", \"vendor_name\"])\n",
        "vendors = [v.to_dict() for v in vendors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read vendor data into DataFrame\n",
        "vendors_df = pd.json_normalize(vendors)\n",
        "vendors_df[\"properties.domain\"] = vendors_df[\"properties.domain\"].astype(\"category\")\n",
        "if RUN_MODE == RunMode.FULL:\n",
        "    write_json_records(vendors_df, \"vendor_all.json\")\n",
        "\n",
        "# filter any custom object vendors missing their domain property\n",
        "# these were used for testing the vendor object import\n",
        "vendors_df = vendors_df[~vendors_df[\"properties.domain\"].isna()]\n",
        "if RUN_MODE == RunMode.FULL:\n",
        "    write_json_records(vendors_df, \"vendor_with_domains.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get association definitions\n",
        "\n",
        "In this section we get all definitions for association types on the vendor custom object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vendor_association_defs = pd.DataFrame(columns=[\"name\", \"id\", \"type\"])\n",
        "for association_type in ASSOCIATION_TYPES:\n",
        "    # association definitions for the vendor custom object\n",
        "    # i.e. vendors --> emails\n",
        "    #      vendors --> meetings\n",
        "    forward = hubspot.crm.associations.schema.types_api.get_all(\"vendors\", association_type)\n",
        "    df1 = pd.json_normalize(forward.to_dict(), \"results\")\n",
        "    df1[\"type\"] = association_type\n",
        "    df1[\"dir\"] = \"forward\"\n",
        "    # reverse association definitions for the vendor custom object\n",
        "    # i.e. emails --> vendors\n",
        "    #      meetings --> vendors\n",
        "    reverse = hubspot.crm.associations.schema.types_api.get_all(association_type, \"vendors\")\n",
        "    df2 = pd.json_normalize(reverse.to_dict(), \"results\")\n",
        "    df2[\"type\"] = association_type\n",
        "    df2[\"dir\"] = \"reverse\"\n",
        "    # combine forward and reverse for this association_type\n",
        "    df = pd.concat((df1, df2))\n",
        "    # merge with the overall result\n",
        "    vendor_association_defs = vendor_association_defs.merge(df, how=\"outer\")\n",
        "\n",
        "if RUN_MODE == RunMode.FULL:\n",
        "    write_json_records(vendor_association_defs, \"vendor_associations.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vendor matching\n",
        "\n",
        "This section joins vendor company objects (that have activities) with the corresponding vendor custom object\n",
        "using a couple strategies:\n",
        "\n",
        "- LEFT on domain\n",
        "- LEFT on name\n",
        "\n",
        "These results are joined together to allow us to see which company objects could not be matched with a custom object\n",
        "using either strategy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if RUN_MODE == RunMode.FULL:\n",
        "    # combine the company vendors and custom object vendors into a single DataFrame with all columns\n",
        "    # using an LEFT JOIN on domain\n",
        "    # keeps records that have at least company vendor details\n",
        "    joined_vendors_df_domain = vendor_companies_df.merge(\n",
        "        vendors_df, on=\"properties.domain\", how=\"left\", suffixes=(\"_company\", \"_custom\")\n",
        "    )\n",
        "\n",
        "    # filter mismatched companies for those with any activities\n",
        "    missing_custom_with_activity_criteria_domain = joined_vendors_df_domain[\"id_custom\"].isna() & any(\n",
        "        [joined_vendors_df_domain[f\"associations.{a}.results\"].count() > 0 for a in ASSOCIATION_TYPES]\n",
        "    )\n",
        "    missing_custom_with_activity_domain = joined_vendors_df_domain[missing_custom_with_activity_criteria_domain]\n",
        "    # sort by name\n",
        "    missing_custom_with_activity_domain = missing_custom_with_activity_domain.sort_values(\"properties.name\")\n",
        "    # rename joined columns\n",
        "    renames_domain = {\"id_company\": \"id\", \"properties.hs_object_id_company\": \"properties.hs_object_id\"}\n",
        "    renamed_missing_domain = missing_custom_with_activity_domain.rename(columns=renames_domain)\n",
        "    # select just the columns for later joining\n",
        "    select_domain = list(renames_domain.values()) + [\"properties.company_type\", \"properties.domain\", \"properties.name\"]\n",
        "    missing_output_domain = renamed_missing_domain[select_domain]\n",
        "    write_json_records(missing_output_domain, \"company_vendor_mismatched_domain.json\")\n",
        "\n",
        "    # combine the company vendors and custom object vendors into a single DataFrame with all columns\n",
        "    # using an LEFT JOIN on name\n",
        "    # keeps records that have at least company vendor details\n",
        "    joined_vendors_df_name = vendor_companies_df.merge(\n",
        "        vendors_df, left_on=\"properties.name\", right_on=\"properties.vendor_name\", how=\"left\", suffixes=(\"_company\", \"_custom\")\n",
        "    )\n",
        "\n",
        "    # filter mismatched companies for those with any activities\n",
        "    missing_custom_with_activity_criteria_name = joined_vendors_df_name[\"id_custom\"].isna() & any(\n",
        "        [joined_vendors_df_name[f\"associations.{a}.results\"].count() > 0 for a in ASSOCIATION_TYPES]\n",
        "    )\n",
        "    missing_custom_with_activity_name = joined_vendors_df_name[missing_custom_with_activity_criteria_name]\n",
        "    # sort by name\n",
        "    missing_custom_with_activity_name = missing_custom_with_activity_name.sort_values(\"properties.name\")\n",
        "    # rename joined columns\n",
        "    renames_name = {\n",
        "        \"id_company\": \"id\",\n",
        "        \"properties.hs_object_id_company\": \"properties.hs_object_id\",\n",
        "        \"properties.domain_company\": \"properties.domain\",\n",
        "    }\n",
        "    renamed_missing_name = missing_custom_with_activity_name.rename(columns=renames_name)\n",
        "    # select just the columns for later joining\n",
        "    select_name = list(renames_name.values()) + [\"properties.company_type\", \"properties.name\"]\n",
        "    missing_name = renamed_missing_name[select_name]\n",
        "    write_json_records(missing_name, \"company_vendor_mismatched_name.json\")\n",
        "\n",
        "    # merge the two DataFrames together\n",
        "    # these are all the company vendors with activities that didn't have a matching custom vendor object\n",
        "    # either on domain or name\n",
        "    merged_missing = missing_output_domain.merge(missing_name, how=\"outer\", on=\"properties.domain\")\n",
        "    # sort the columns\n",
        "    sorted_cols = sorted(merged_missing.columns.to_list())\n",
        "    merged_missing = merged_missing.reindex(columns=sorted_cols)\n",
        "    # backfill missing values from the nearest column\n",
        "    # since the columns are sorted, when e.g. column_x is missing, it will be filled from column_y\n",
        "    merged_missing = merged_missing.replace(\"\", pd.NA).bfill(axis=1)\n",
        "    # rename joined columns now that there is a value for each\n",
        "    renames = {\n",
        "        \"properties.name_x\": \"properties.name\",\n",
        "        \"properties.hs_object_id_x\": \"properties.hs_object_id\",\n",
        "        \"id_x\": \"id\",\n",
        "        \"properties.company_type_x\": \"properties.company_type\",\n",
        "    }\n",
        "    merged_missing = merged_missing.rename(columns=renames)\n",
        "    # select a limited list of columns for output\n",
        "    select = [\"properties.domain\"] + list(renames.values())\n",
        "    selected_output = merged_missing[select]\n",
        "    write_json_records(selected_output, \"vendors_merged_missing_custom_with_activity.json\")\n",
        "    # adds a separator row for CSV output into markdown table format\n",
        "    separator_row = pd.DataFrame([map(lambda x: \"-----\", select)], columns=select)\n",
        "    csv_output = pd.concat([separator_row, selected_output], ignore_index=True)\n",
        "    # escape the pipe character, our separator for markdown table format\n",
        "    csv_output.replace(\"|\", \"\\|\", inplace=True)\n",
        "    # write to CSV into markdown table format\n",
        "    csv_output.to_csv(\"data/vendors_merged_missing_custom_with_activity.csv\", index=False, sep=\"|\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup vendor associations\n",
        "\n",
        "In this section we define association objects to create, between the vendor custom object and each type in `ASSOCIATION_TYPES`.\n",
        "\n",
        "Vendor company objects serve as the source for existing assocations, and we merge these with the `id` of the related vendor\n",
        "custom object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rename joined columns\n",
        "renames = {\"id_custom\": \"id\", \"properties.hs_object_id_custom\": \"properties.hs_object_id\"}\n",
        "# join the vendors company objects with vendor custom objects records\n",
        "# using an OUTER JOIN on domain\n",
        "joined_vendors_df = vendor_companies_df.merge(\n",
        "    vendors_df, on=\"properties.domain\", how=\"outer\", suffixes=(\"_company\", \"_custom\")\n",
        ").rename(columns=renames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vendor_associations(vendor_company_record: pd.Series, association_type: str):\n",
        "    \"\"\"\n",
        "    Create a list of association objects, from the given vendor company's associations,\n",
        "    of the given type, for both directions.\n",
        "    \"\"\"\n",
        "    association_results = vendor_company_record[f\"associations.{association_type}.results\"]\n",
        "    associations = association_results if isinstance(association_results, list) else None\n",
        "    vendor_id = vendor_company_record[\"id\"]\n",
        "\n",
        "    if associations and vendor_id:\n",
        "        forward = [\n",
        "            {\"from\": {\"id\": vendor_id}, \"to\": {\"id\": a[\"id\"]}, \"dir\": \"forward\", \"type\": association_type}\n",
        "            for a in associations\n",
        "        ]\n",
        "        reverse = [\n",
        "            {\"from\": {\"id\": a[\"id\"]}, \"to\": {\"id\": vendor_id}, \"dir\": \"reverse\", \"type\": association_type}\n",
        "            for a in associations\n",
        "        ]\n",
        "        return forward + reverse\n",
        "    else:\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vendor_associations_df = pd.DataFrame(columns=[\"from.id\", \"to.id\", \"dir\", \"type\"])\n",
        "\n",
        "for association_type in ASSOCIATION_TYPES:\n",
        "    applied_associations = (\n",
        "        joined_vendors_df\n",
        "            # apply the function to each row for this association type\n",
        "            # each apply returns a list, which are all combined into a series\n",
        "            .apply(create_vendor_associations, axis=1, association_type=association_type)\n",
        "            # drop duplicates (e.g. rows with empty lists)\n",
        "            .drop_duplicates()\n",
        "            # each row is a list itself, so explode into one giant list\n",
        "            .explode()\n",
        "            # finally, drop NA values\n",
        "            .dropna()\n",
        "    )\n",
        "    if len(applied_associations) > 0:\n",
        "        # now each row is a dict\n",
        "        # noramlize_json turns this into a DataFrame with columns from the dict keys\n",
        "        applied_associations_df = pd.json_normalize(applied_associations.to_list())\n",
        "        # merge with the complete set\n",
        "        vendor_associations_df = vendor_associations_df.merge(applied_associations_df, how=\"outer\")\n",
        "\n",
        "# now merge all created assocations with the definitions\n",
        "# to get the definition name and id\n",
        "# drop NA values for the outer join when no activities of a given type are present\n",
        "vendor_associations_df = vendor_associations_df.merge(vendor_association_defs, how=\"outer\", on=[\"dir\", \"type\"]).dropna()\n",
        "\n",
        "if RUN_MODE < RunMode.LIVE:\n",
        "    write_json_records(vendor_associations_df, \"associations_create.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create vendor associations\n",
        "\n",
        "Now all the data preparation is done, we make the API calls to create the associations.\n",
        "\n",
        "The API calls are done in batches according to the direction (forward or reverse) and type\n",
        "of association being created.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# grouping the associations by direction, type, and ID\n",
        "# each group will be sent in a batch request\n",
        "vendor_association_groups = vendor_associations_df.groupby(by=[\"dir\", \"type\", \"id\"])\n",
        "\n",
        "for group in vendor_association_groups.groups:\n",
        "    # group here is a tuple of the grouping column values\n",
        "    group_dir, group_type, group_id = group\n",
        "    # required param for each association, identifies the association type being created\n",
        "    types = [AssociationSpec(association_category=\"USER_DEFINED\", association_type_id=group_id)]\n",
        "    # get the actual data for this group as a DataFrame\n",
        "    group_df = vendor_association_groups.get_group(group)\n",
        "    # convert to the required inputs format: list[PublicAssociationMultiPost]\n",
        "    inputs = group_df.apply(lambda d: PublicAssociationMultiPost(types, d[\"from.id\"], d[\"to.id\"]), axis=1, result_type=\"reduce\").to_list()\n",
        "\n",
        "    # now create the batch request for these inputs\n",
        "    batch = BatchInputPublicAssociationMultiPost(inputs=inputs)\n",
        "    # decide on the from and to object\n",
        "    from_object = \"vendors\" if group_dir == \"forward\" else group_type\n",
        "    to_object = group_type if group_dir == \"forward\" else \"vendors\"\n",
        "\n",
        "    if RUN_MODE == RunMode.LIVE:\n",
        "        # call the API to create associations for the batch\n",
        "        hubspot.crm.associations.v4.batch_api.create(from_object, to_object, batch)\n",
        "    elif RUN_MODE == RunMode.DRY:\n",
        "        # call the API to create a single association from the batch\n",
        "        batch.inputs = batch.inputs[0:1]\n",
        "        print(batch.inputs)\n",
        "        response = hubspot.crm.associations.v4.batch_api.create(from_object, to_object, batch)\n",
        "        print(response)\n",
        "    else:\n",
        "        print(f\"{from_object} --> {to_object}: {len(batch.inputs)}\")\n",
        "\n",
        "print(\"total associations:\", vendor_associations_df.shape[0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
